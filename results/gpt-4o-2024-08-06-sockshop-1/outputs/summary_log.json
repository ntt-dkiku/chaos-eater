[
    {
        "name": "overall_summary",
        "token_usage": {
            "input_tokens": 18879,
            "output_tokens": 404,
            "total_tokens": 19283
        },
        "message_history": [
            [
                "System: You are a helpful AI assistant for Chaos Engineering.\nGiven a summary of a Chaos Engineering cycle, please elaborate the summary.\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{\"properties\": {\"summary\": {\"title\": \"Summary\", \"type\": \"string\"}}, \"required\": [\"summary\"]}\n```\nHuman: Here is the overview of a Chaos Engineering Cycle:\n# Here is a Chaos Engineering cycle\n## Step 0. User-input understanding\n### Here is the overview of user inputs:\nThe system consists of the following K8s manifest(s):K8s manifest: sock-shop-2/manifests/00-sock-shop-ns.yaml\n```yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: sock-shop\n\n```\nSummary of sock-shop-2/manifests/00-sock-shop-ns.yaml:\n- This manifest defines a Kubernetes Namespace.\n- The Namespace is named 'sock-shop'.\n- Namespaces are used to organize and manage resources within a Kubernetes cluster.\n\nK8s manifest: sock-shop-2/manifests/01-carts-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: carts\n  labels:\n    name: carts\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: carts\n  template:\n    metadata:\n      labels:\n        name: carts\n    spec:\n      containers:\n      - name: carts\n        image: weaveworksdemos/carts:0.4.8\n        env:\n         - name: JAVA_OPTS\n           value: -Xms64m -Xmx128m -XX:+UseG1GC -Djava.security.egd=file:/dev/urandom -Dspring.zipkin.enabled=false\n        resources:\n          limits:\n            cpu: 300m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n            add:\n              - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-volume\n      volumes:\n        - name: tmp-volume\n          emptyDir:\n            medium: Memory\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/01-carts-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'carts' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'carts' application running.\n- The Deployment uses the Docker image 'weaveworksdemos/carts:0.4.8'.\n- Environment variables are set for Java options to optimize memory usage and disable certain features.\n- Resource limits and requests are defined, with a maximum of 300m CPU and 500Mi memory, and a minimum of 100m CPU and 200Mi memory.\n- The application listens on port 80 within the container.\n- Security context is configured to run the container as a non-root user with specific capabilities.\n- The root filesystem is set to be read-only for security purposes.\n- A temporary volume is mounted at '/tmp' using an in-memory empty directory.\n- The Deployment is scheduled to run on nodes with the Linux operating system.\n\nK8s manifest: sock-shop-2/manifests/02-carts-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: carts\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: carts\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 80\n    targetPort: 80\n  selector:\n    name: carts\n\n```\nSummary of sock-shop-2/manifests/02-carts-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'carts'.\n- It is annotated to enable Prometheus scraping with 'prometheus.io/scrape: true'.\n- The Service is labeled with 'name: carts'.\n- It is deployed in the 'sock-shop' namespace.\n- The Service exposes port 80 and directs traffic to the same port on the selected pods.\n- It uses a selector to target pods with the label 'name: carts'.\n\nK8s manifest: sock-shop-2/manifests/03-carts-db-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: carts-db\n  labels:\n    name: carts-db\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: carts-db\n  template:\n    metadata:\n      labels:\n        name: carts-db\n    spec:\n      containers:\n      - name: carts-db\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n        securityContext:\n          capabilities:\n            drop:\n              - all\n            add:\n              - CHOWN\n              - SETGID\n              - SETUID\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-volume\n      volumes:\n        - name: tmp-volume\n          emptyDir:\n            medium: Memory\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/03-carts-db-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'carts-db' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'carts-db' pod running.\n- The pods are selected based on the label 'name: carts-db'.\n- Each pod runs a single container using the 'mongo' image.\n- The container exposes port 27017, which is commonly used by MongoDB.\n- Security settings are applied to drop all capabilities and only add CHOWN, SETGID, and SETUID.\n- The root filesystem of the container is set to be read-only for security purposes.\n- A temporary volume is mounted at '/tmp' using an in-memory emptyDir volume.\n- The pods are scheduled to run on nodes with the operating system labeled as 'linux'.\n\nK8s manifest: sock-shop-2/manifests/04-carts-db-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: carts-db\n  labels:\n    name: carts-db\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 27017\n    targetPort: 27017\n  selector:\n    name: carts-db\n\n```\nSummary of sock-shop-2/manifests/04-carts-db-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'carts-db'.\n- It is located in the 'sock-shop' namespace.\n- The Service is associated with pods that have the label 'name: carts-db'.\n- It exposes port 27017, which is also the target port for the pods.\n\nK8s manifest: sock-shop-2/manifests/05-catalogue-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalogue\n  labels:\n    name: catalogue\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: catalogue\n  template:\n    metadata:\n      labels:\n        name: catalogue\n    spec:\n      containers:\n      - name: catalogue\n        image: weaveworksdemos/catalogue:0.3.5\n        command: [\"/app\"]\n        args:\n        - -port=80\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n            add:\n              - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 300\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 180\n          periodSeconds: 3\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/05-catalogue-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'catalogue' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'catalogue' application running.\n- The Deployment uses the Docker image 'weaveworksdemos/catalogue:0.3.5'.\n- The application runs with the command '/app' and listens on port 80.\n- Resource limits are set to 200m CPU and 200Mi memory, with requests for 100m CPU and 100Mi memory.\n- The container is configured to run as a non-root user with user ID 10001.\n- Security settings include dropping all capabilities except 'NET_BIND_SERVICE' and using a read-only root filesystem.\n- Liveness and readiness probes are configured to check the '/health' endpoint on port 80, with specific initial delays and periods.\n- The Deployment is scheduled to run on nodes with the Linux operating system.\n\nK8s manifest: sock-shop-2/manifests/06-catalogue-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: catalogue\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: catalogue\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 80\n    targetPort: 80\n  selector:\n    name: catalogue\n\n```\nSummary of sock-shop-2/manifests/06-catalogue-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The service is named 'catalogue'.\n- It is annotated for Prometheus scraping with 'prometheus.io/scrape: true'.\n- The service is labeled with 'name: catalogue'.\n- It is deployed in the 'sock-shop' namespace.\n- The service exposes port 80 and directs traffic to the same port on the selected pods.\n- It selects pods with the label 'name: catalogue' to route traffic to.\n\nK8s manifest: sock-shop-2/manifests/07-catalogue-db-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalogue-db\n  labels:\n    name: catalogue-db\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: catalogue-db\n  template:\n    metadata:\n      labels:\n        name: catalogue-db\n    spec:\n      containers:\n      - name: catalogue-db\n        image: weaveworksdemos/catalogue-db:0.3.0\n        env:\n          - name: MYSQL_ROOT_PASSWORD\n            value: fake_password\n          - name: MYSQL_DATABASE\n            value: socksdb\n        ports:\n        - name: mysql\n          containerPort: 3306\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/07-catalogue-db-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'catalogue-db' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas (instances) of the 'catalogue-db' pod running.\n- The pods are selected based on the label 'name: catalogue-db'.\n- Each pod runs a container named 'catalogue-db' using the image 'weaveworksdemos/catalogue-db:0.3.0'.\n- The container is configured with environment variables for 'MYSQL_ROOT_PASSWORD' and 'MYSQL_DATABASE'.\n- The container exposes port 3306, which is typically used for MySQL databases.\n- The pods are scheduled to run on nodes with the operating system labeled as 'linux'.\n\nK8s manifest: sock-shop-2/manifests/08-catalogue-db-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: catalogue-db\n  labels:\n    name: catalogue-db\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 3306\n    targetPort: 3306\n  selector:\n    name: catalogue-db\n\n```\nSummary of sock-shop-2/manifests/08-catalogue-db-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'catalogue-db'.\n- It is located in the 'sock-shop' namespace.\n- The Service is configured to expose port 3306.\n- It targets port 3306 on the pods it selects.\n- The Service uses a selector to match pods with the label 'name: catalogue-db'.\n\nK8s manifest: sock-shop-2/manifests/09-front-end-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-end\n  namespace: sock-shop\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: front-end\n  template:\n    metadata:\n      labels:\n        name: front-end\n    spec:\n      containers:\n      - name: front-end\n        image: weaveworksdemos/front-end:0.3.12\n        resources:\n          limits:\n            cpu: 300m\n            memory: 1000Mi\n          requests:\n            cpu: 100m\n            memory: 300Mi\n        ports:\n        - containerPort: 8079\n        env:\n        - name: SESSION_REDIS\n          value: \"true\"\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n          readOnlyRootFilesystem: true\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 300\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 30\n          periodSeconds: 3\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n```\nSummary of sock-shop-2/manifests/09-front-end-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'front-end' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 1 replica of the front-end application running.\n- The Deployment uses a selector to match pods with the label 'name: front-end'.\n- The pod template includes a single container named 'front-end'.\n- The container uses the image 'weaveworksdemos/front-end:0.3.12'.\n- Resource limits are set for the container: 300m CPU and 1000Mi memory.\n- Resource requests are set for the container: 100m CPU and 300Mi memory.\n- The container exposes port 8079.\n- An environment variable 'SESSION_REDIS' is set to 'true'.\n- Security context is configured to run the container as a non-root user with user ID 10001.\n- All Linux capabilities are dropped, and the root filesystem is set to read-only.\n- A liveness probe is configured to check the root path '/' on port 8079, with an initial delay of 300 seconds and a period of 3 seconds.\n- A readiness probe is also configured to check the root path '/' on port 8079, with an initial delay of 30 seconds and a period of 3 seconds.\n- The node selector ensures that the pod runs on nodes with the operating system labeled as Linux.\n\nK8s manifest: sock-shop-2/manifests/10-front-end-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: front-end\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: front-end\n  namespace: sock-shop\nspec:\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort: 8079\n    nodePort: 30001\n  selector:\n    name: front-end\n\n```\nSummary of sock-shop-2/manifests/10-front-end-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'front-end'.\n- It is located in the 'sock-shop' namespace.\n- The Service type is 'NodePort', which exposes the service on each Node's IP at a static port.\n- It listens on port 80 and forwards traffic to target port 8079 on the pods.\n- The nodePort is set to 30001, which is the port on each node where the service can be accessed externally.\n- The Service is configured to select pods with the label 'name: front-end'.\n- An annotation is included to enable Prometheus scraping for monitoring purposes.\n\nK8s manifest: sock-shop-2/manifests/11-orders-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: orders\n  labels:\n    name: orders\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: orders\n  template:\n    metadata:\n      labels:\n        name: orders\n    spec:\n      containers:\n      - name: orders\n        image: weaveworksdemos/orders:0.4.7\n        env:\n         - name: JAVA_OPTS\n           value: -Xms64m -Xmx128m -XX:+UseG1GC -Djava.security.egd=file:/dev/urandom -Dspring.zipkin.enabled=false\n        resources:\n          limits:\n            cpu: 500m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 300Mi\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n            add:\n              - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-volume\n      volumes:\n        - name: tmp-volume\n          emptyDir:\n            medium: Memory\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/11-orders-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'orders' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'orders' application running.\n- The Deployment uses the Docker image 'weaveworksdemos/orders:0.4.7'.\n- Environment variables are set for Java options to optimize memory usage and disable certain features.\n- Resource limits and requests are defined, with a maximum of 500m CPU and 500Mi memory, and a minimum of 100m CPU and 300Mi memory.\n- The application listens on port 80 inside the container.\n- Security context is configured to run the container as a non-root user with specific capabilities and a read-only root filesystem.\n- A temporary volume is mounted at '/tmp' using an in-memory empty directory.\n- The Deployment is scheduled to run on nodes with the Linux operating system.\n\nK8s manifest: sock-shop-2/manifests/12-orders-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: orders\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: orders\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 80\n    targetPort: 80\n  selector:\n    name: orders\n\n```\nSummary of sock-shop-2/manifests/12-orders-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'orders'.\n- It is annotated for Prometheus scraping, which means it is set up to be monitored by Prometheus.\n- The Service is labeled with 'name: orders'.\n- It is deployed in the 'sock-shop' namespace.\n- The Service exposes port 80 and directs traffic to the same port on the selected pods.\n- The Service selects pods with the label 'name: orders' to route traffic to them.\n\nK8s manifest: sock-shop-2/manifests/13-orders-db-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: orders-db\n  labels:\n    name: orders-db\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: orders-db\n  template:\n    metadata:\n      labels:\n        name: orders-db\n    spec:\n      containers:\n      - name: orders-db\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n        securityContext:\n          capabilities:\n            drop:\n              - all\n            add:\n              - CHOWN\n              - SETGID\n              - SETUID\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-volume\n      volumes:\n        - name: tmp-volume\n          emptyDir:\n            medium: Memory\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/13-orders-db-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'orders-db' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'orders-db' pod running.\n- The pods are selected based on the label 'name: orders-db'.\n- Each pod runs a single container using the 'mongo' image.\n- The container exposes port 27017 for MongoDB.\n- Security settings are applied to drop all capabilities and add specific ones like CHOWN, SETGID, and SETUID.\n- The root filesystem of the container is set to read-only for security.\n- A temporary volume is mounted at '/tmp' using an in-memory emptyDir.\n- The pods are scheduled to run on nodes with the operating system labeled as 'linux'.\n\nK8s manifest: sock-shop-2/manifests/14-orders-db-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: orders-db\n  labels:\n    name: orders-db\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 27017\n    targetPort: 27017\n  selector:\n    name: orders-db\n\n```\nSummary of sock-shop-2/manifests/14-orders-db-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'orders-db'.\n- It is located in the 'sock-shop' namespace.\n- The Service is configured to expose port 27017.\n- It targets the same port (27017) on the pods it selects.\n- The Service uses a selector to find pods with the label 'name: orders-db'.\n\nK8s manifest: sock-shop-2/manifests/15-payment-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payment\n  labels:\n    name: payment\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: payment\n  template:\n    metadata:\n      labels:\n        name: payment\n    spec:\n      containers:\n      - name: payment\n        image: weaveworksdemos/payment:0.4.3\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 99m\n            memory: 100Mi\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n            add:\n              - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 300\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 180\n          periodSeconds: 3\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/15-payment-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'payment' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'payment' application running.\n- The Deployment uses the Docker image 'weaveworksdemos/payment:0.4.3'.\n- Resource limits are set for the container, with a maximum of 200m CPU and 200Mi memory, and requests for 99m CPU and 100Mi memory.\n- The container listens on port 80.\n- Security settings ensure the container runs as a non-root user with user ID 10001, and the root filesystem is read-only.\n- The container has a liveness probe and a readiness probe, both checking the '/health' endpoint on port 80.\n- The liveness probe starts after 300 seconds and checks every 3 seconds, while the readiness probe starts after 180 seconds and also checks every 3 seconds.\n- The Deployment is configured to run on nodes with the Linux operating system.\n\nK8s manifest: sock-shop-2/manifests/16-payment-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: payment\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: payment\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 80\n    targetPort: 80\n  selector:\n    name: payment\n\n```\nSummary of sock-shop-2/manifests/16-payment-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'payment'.\n- It is annotated for Prometheus scraping, which means it is set up to be monitored by Prometheus.\n- The Service is labeled with 'name: payment'.\n- It is deployed in the 'sock-shop' namespace.\n- The Service exposes port 80 and directs traffic to the same port on the selected pods.\n- The Service uses a selector to target pods with the label 'name: payment'.\n\nK8s manifest: sock-shop-2/manifests/17-queue-master-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: queue-master\n  labels:\n    name: queue-master\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: queue-master\n  template:\n    metadata:\n      labels:\n        name: queue-master\n    spec:\n      containers:\n      - name: queue-master\n        image: weaveworksdemos/queue-master:0.3.1\n        env:\n         - name: JAVA_OPTS\n           value: -Xms64m -Xmx128m -XX:+UseG1GC -Djava.security.egd=file:/dev/urandom -Dspring.zipkin.enabled=false\n        resources:\n          limits:\n            cpu: 300m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 300Mi\n        ports:\n        - containerPort: 80\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/17-queue-master-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'queue-master' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas (copies) of the 'queue-master' application running.\n- The Deployment uses a container image 'weaveworksdemos/queue-master:0.3.1'.\n- Environment variables are set for the container, including Java options for memory management and garbage collection.\n- Resource limits and requests are defined, with a maximum of 300m CPU and 500Mi memory, and a minimum of 100m CPU and 300Mi memory.\n- The container exposes port 80 for network access.\n- The Deployment is configured to run on nodes with the Linux operating system.\n\nK8s manifest: sock-shop-2/manifests/18-queue-master-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: queue-master\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: queue-master\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 80\n    targetPort: 80\n  selector:\n    name: queue-master\n```\nSummary of sock-shop-2/manifests/18-queue-master-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The service is named 'queue-master'.\n- It is annotated for Prometheus scraping with 'prometheus.io/scrape: true'.\n- The service is labeled with 'name: queue-master'.\n- It is deployed in the 'sock-shop' namespace.\n- The service exposes port 80 and directs traffic to the same port on the selected pods.\n- It selects pods with the label 'name: queue-master'.\n\nK8s manifest: sock-shop-2/manifests/19-rabbitmq-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rabbitmq\n  labels:\n    name: rabbitmq\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: rabbitmq\n  template:\n    metadata:\n      labels:\n        name: rabbitmq\n      annotations:\n        prometheus.io/scrape: \"false\"\n    spec:\n      containers:\n      - name: rabbitmq\n        image: rabbitmq:3.6.8-management\n        ports:\n        - containerPort: 15672\n          name: management\n        - containerPort: 5672\n          name: rabbitmq\n        securityContext:\n          capabilities:\n            drop:\n              - all\n            add:\n              - CHOWN\n              - SETGID\n              - SETUID\n              - DAC_OVERRIDE\n          readOnlyRootFilesystem: true\n      - name: rabbitmq-exporter\n        image: kbudde/rabbitmq-exporter\n        ports:\n        - containerPort: 9090\n          name: exporter\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/19-rabbitmq-dep.yaml:\n- This manifest defines a Deployment for RabbitMQ in Kubernetes.\n- The Deployment is named 'rabbitmq' and is located in the 'sock-shop' namespace.\n- It specifies 2 replicas of the RabbitMQ application to be deployed.\n- The Deployment uses a selector to match pods with the label 'name: rabbitmq'.\n- The pod template includes two containers: one for RabbitMQ and another for RabbitMQ Exporter.\n- The RabbitMQ container uses the image 'rabbitmq:3.6.8-management' and exposes ports 15672 (management) and 5672 (RabbitMQ service).\n- The RabbitMQ container has a security context that drops all capabilities and adds specific ones like CHOWN, SETGID, SETUID, and DAC_OVERRIDE, and it uses a read-only root filesystem.\n- The RabbitMQ Exporter container uses the image 'kbudde/rabbitmq-exporter' and exposes port 9090 for metrics.\n- The Deployment specifies a node selector to ensure that the pods run on nodes with the operating system labeled as Linux.\n- Annotations are set to prevent Prometheus from scraping metrics from this deployment.\n\nK8s manifest: sock-shop-2/manifests/20-rabbitmq-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: rabbitmq\n  annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n  labels:\n    name: rabbitmq\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 5672\n    name: rabbitmq\n    targetPort: 5672\n  - port: 9090\n    name: exporter\n    targetPort: exporter\n    protocol: TCP\n  selector:\n    name: rabbitmq\n\n```\nSummary of sock-shop-2/manifests/20-rabbitmq-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'rabbitmq'.\n- It is annotated for Prometheus scraping on port 9090.\n- The Service is located in the 'sock-shop' namespace.\n- It exposes two ports: 5672 for RabbitMQ and 9090 for an exporter.\n- The Service uses TCP protocol for communication.\n- It selects pods with the label 'name: rabbitmq'.\n\nK8s manifest: sock-shop-2/manifests/21-session-db-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: session-db\n  labels:\n    name: session-db\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: session-db\n  template:\n    metadata:\n      labels:\n        name: session-db\n      annotations:\n        prometheus.io.scrape: \"false\"\n    spec:\n      containers:\n      - name: session-db\n        image: redis:alpine\n        ports:\n        - name: redis\n          containerPort: 6379\n        securityContext:\n          capabilities:\n            drop:\n              - all\n            add:\n              - CHOWN\n              - SETGID\n              - SETUID\n          readOnlyRootFilesystem: true\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/21-session-db-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'session-db' and is located in the 'sock-shop' namespace.\n- It specifies 2 replicas of the pod to be created.\n- The pods are selected based on the label 'name: session-db'.\n- Each pod runs a container using the 'redis:alpine' image.\n- The container exposes port 6379, which is commonly used by Redis.\n- Security settings are applied to drop all capabilities and only add CHOWN, SETGID, and SETUID.\n- The root filesystem of the container is set to be read-only for security purposes.\n- The pods are scheduled to run on nodes with the operating system labeled as Linux.\n\nK8s manifest: sock-shop-2/manifests/22-session-db-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: session-db\n  labels:\n    name: session-db\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 6379\n    targetPort: 6379\n  selector:\n    name: session-db\n\n```\nSummary of sock-shop-2/manifests/22-session-db-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'session-db'.\n- It is located in the 'sock-shop' namespace.\n- The Service listens on port 6379 and forwards traffic to the same port on the target pods.\n- It uses a selector to target pods with the label 'name: session-db'.\n\nK8s manifest: sock-shop-2/manifests/23-shipping-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: shipping\n  labels:\n    name: shipping\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: shipping\n  template:\n    metadata:\n      labels:\n        name: shipping\n    spec:\n      containers:\n      - name: shipping\n        image: weaveworksdemos/shipping:0.4.8\n        env:\n         - name: ZIPKIN\n           value: zipkin.jaeger.svc.cluster.local\n         - name: JAVA_OPTS\n           value: -Xms64m -Xmx128m -XX:+UseG1GC -Djava.security.egd=file:/dev/urandom -Dspring.zipkin.enabled=false\n        resources:\n          limits:\n            cpu: 300m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 300Mi\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n            add:\n              - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-volume\n      volumes:\n        - name: tmp-volume\n          emptyDir:\n            medium: Memory\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/23-shipping-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'shipping' and is located in the 'sock-shop' namespace.\n- It specifies 2 replicas of the 'shipping' application to be run.\n- The Deployment uses the Docker image 'weaveworksdemos/shipping:0.4.8'.\n- Environment variables 'ZIPKIN' and 'JAVA_OPTS' are set for the container.\n- Resource limits are set to 300m CPU and 500Mi memory, with requests for 100m CPU and 300Mi memory.\n- The container exposes port 80.\n- Security context is configured to run the container as a non-root user with user ID 10001.\n- The container has a read-only root filesystem and specific capabilities are dropped and added.\n- A temporary volume is mounted at '/tmp' using an in-memory emptyDir volume.\n- The Deployment is scheduled to run on nodes with the Linux operating system.\n\nK8s manifest: sock-shop-2/manifests/24-shipping-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: shipping\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: shipping\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 80\n    targetPort: 80\n  selector:\n    name: shipping\n\n\n```\nSummary of sock-shop-2/manifests/24-shipping-svc.yaml:\n- This is a Kubernetes Service manifest.\n- The service is named 'shipping'.\n- It is annotated for Prometheus scraping with 'prometheus.io/scrape: true'.\n- The service is labeled with 'name: shipping'.\n- It is deployed in the 'sock-shop' namespace.\n- The service exposes port 80 and directs traffic to the same port on the selected pods.\n- It selects pods with the label 'name: shipping'.\n\nK8s manifest: sock-shop-2/manifests/25-user-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user\n  labels:\n    name: user\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: user\n  template:\n    metadata:\n      labels:\n        name: user\n    spec:\n      containers:\n      - name: user\n        image: weaveworksdemos/user:0.4.7\n        resources:\n          limits:\n            cpu: 300m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 80\n        env:\n        - name: mongo\n          value: user-db:27017\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n            add:\n              - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 300\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 180\n          periodSeconds: 3\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/25-user-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'user' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'user' application running.\n- The Deployment uses the Docker image 'weaveworksdemos/user:0.4.7'.\n- Resource limits are set for the container: 300m CPU and 200Mi memory.\n- Resource requests are set for the container: 100m CPU and 100Mi memory.\n- The container exposes port 80.\n- An environment variable 'mongo' is set with the value 'user-db:27017'.\n- Security context is configured to run the container as a non-root user with user ID 10001.\n- All capabilities are dropped except 'NET_BIND_SERVICE', and the root filesystem is set to read-only.\n- A liveness probe is configured to check the '/health' endpoint on port 80, starting after 300 seconds and checking every 3 seconds.\n- A readiness probe is also configured to check the '/health' endpoint on port 80, starting after 180 seconds and checking every 3 seconds.\n- The Deployment is scheduled to run on nodes with the operating system labeled as Linux.\n\nK8s manifest: sock-shop-2/manifests/26-user-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: user\n  annotations:\n        prometheus.io/scrape: 'true'\n  labels:\n    name: user\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 80\n    targetPort: 80\n  selector:\n    name: user\n\n\n```\nSummary of sock-shop-2/manifests/26-user-svc.yaml:\n- This is a Kubernetes Service manifest.\n- The service is named 'user'.\n- It is annotated for Prometheus scraping with 'prometheus.io/scrape: true'.\n- The service is labeled with 'name: user'.\n- It is deployed in the 'sock-shop' namespace.\n- The service listens on port 80 and forwards traffic to the same port on the selected pods.\n- The service selects pods with the label 'name: user'.\n\nK8s manifest: sock-shop-2/manifests/27-user-db-dep.yaml\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-db\n  labels:\n    name: user-db\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: user-db\n  template:\n    metadata:\n      labels:\n        name: user-db\n    spec:\n      containers:\n      - name: user-db\n        image: weaveworksdemos/user-db:0.3.0\n\n        ports:\n        - name: mongo\n          containerPort: 27017\n        securityContext:\n          capabilities:\n            drop:\n              - all\n            add:\n              - CHOWN\n              - SETGID\n              - SETUID\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-volume\n      volumes:\n        - name: tmp-volume\n          emptyDir:\n            medium: Memory\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n\n```\nSummary of sock-shop-2/manifests/27-user-db-dep.yaml:\n- This manifest defines a Deployment in Kubernetes.\n- The Deployment is named 'user-db' and is located in the 'sock-shop' namespace.\n- It specifies that there should be 2 replicas of the 'user-db' pod running.\n- The pods are selected based on the label 'name: user-db'.\n- Each pod runs a single container using the image 'weaveworksdemos/user-db:0.3.0'.\n- The container exposes port 27017, which is typically used by MongoDB.\n- Security settings are applied to drop all capabilities and only add CHOWN, SETGID, and SETUID.\n- The container's filesystem is set to be read-only, enhancing security.\n- A temporary volume is mounted at '/tmp' using an in-memory emptyDir, which is useful for temporary storage needs.\n- The pods are scheduled to run on nodes with the operating system labeled as 'linux'.\n\nK8s manifest: sock-shop-2/manifests/28-user-db-svc.yaml\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: user-db\n  labels:\n    name: user-db\n  namespace: sock-shop\nspec:\n  ports:\n    # the port that this service should serve on\n  - port: 27017\n    targetPort: 27017\n  selector:\n    name: user-db\n\n\n```\nSummary of sock-shop-2/manifests/28-user-db-svc.yaml:\n- This manifest defines a Kubernetes Service.\n- The Service is named 'user-db'.\n- It is located in the 'sock-shop' namespace.\n- The Service is configured to expose port 27017.\n- It targets the same port (27017) on the pods.\n- The Service selects pods with the label 'name: user-db'.\n\nThe resiliency issues/weaknesses in the system are as follows:\nIssue #0: Missing Resource Requests\n  - details: Pods may not get scheduled if the cluster is under resource pressure, leading to potential downtime.\n  - manifests having the issues: ['sock-shop-2/manifests/03-carts-db-dep.yaml', 'sock-shop-2/manifests/07-catalogue-db-dep.yaml', 'sock-shop-2/manifests/13-orders-db-dep.yaml', 'sock-shop-2/manifests/19-rabbitmq-dep.yaml', 'sock-shop-2/manifests/21-session-db-dep.yaml', 'sock-shop-2/manifests/27-user-db-dep.yaml']\n  - problematic config: The deployments for carts-db, catalogue-db, orders-db, rabbitmq, session-db, and user-db do not specify resource requests.\n\nIssue #1: Single Replica Deployment\n  - details: The front-end deployment has only one replica, which can lead to downtime if the pod fails.\n  - manifests having the issues: ['sock-shop-2/manifests/09-front-end-dep.yaml']\n  - problematic config: spec.replicas: 1\n\nIssue #2: High Initial Delay for Liveness Probe\n  - details: A high initial delay for the liveness probe can delay the detection of a failed pod, leading to longer downtime.\n  - manifests having the issues: ['sock-shop-2/manifests/05-catalogue-dep.yaml', 'sock-shop-2/manifests/09-front-end-dep.yaml', 'sock-shop-2/manifests/15-payment-dep.yaml', 'sock-shop-2/manifests/25-user-dep.yaml']\n  - problematic config: livenessProbe.initialDelaySeconds: 300\n\nIssue #3: Missing Port Specification in Service\n  - details: The service may not function correctly if the port is not specified, leading to connectivity issues.\n  - manifests having the issues: ['sock-shop-2/manifests/02-carts-svc.yaml', 'sock-shop-2/manifests/04-carts-db-svc.yaml', 'sock-shop-2/manifests/06-catalogue-svc.yaml', 'sock-shop-2/manifests/08-catalogue-db-svc.yaml', 'sock-shop-2/manifests/12-orders-svc.yaml', 'sock-shop-2/manifests/14-orders-db-svc.yaml', 'sock-shop-2/manifests/16-payment-svc.yaml', 'sock-shop-2/manifests/18-queue-master-svc.yaml', 'sock-shop-2/manifests/22-session-db-svc.yaml', 'sock-shop-2/manifests/24-shipping-svc.yaml', 'sock-shop-2/manifests/26-user-svc.yaml', 'sock-shop-2/manifests/28-user-db-svc.yaml']\n  - problematic config: The services for carts, carts-db, catalogue, catalogue-db, orders, orders-db, payment, queue-master, session-db, shipping, user, and user-db do not specify the port that the service should serve on.\n\nThe expected type of application on the system (i.e., K8s manfests):\nThe Sock Shop application is a microservices-based e-commerce platform that simulates an online store where users can browse a catalogue of products, add items to a shopping cart, place orders, and make payments. It is designed to demonstrate the use of microservices in a cloud-native environment, showcasing how different services interact within a Kubernetes cluster.; The manifests provided are part of a Kubernetes deployment for a microservices-based application called 'sock-shop'. This is evident from the namespace 'sock-shop' and the naming conventions used in the manifests, such as 'carts', 'catalogue', 'orders', 'payment', 'shipping', 'user', and their respective databases. These components are typical of an e-commerce application, where users can browse a catalogue, add items to a cart, place orders, and make payments. The use of images like 'weaveworksdemos/carts', 'weaveworksdemos/catalogue', and others from the 'weaveworksdemos' repository further supports this assumption, as these are known to be part of the Sock Shop demo application, which is a microservices reference architecture for an e-commerce site.\n\nChaos-Engineering instructions for the system are as follows: - The Chaos-Engineering experiment must be completed within 1 minute.\n\n- When using k6 in steady-state definition, always select a request URL from the following options (other requests are invalid):\n  1. http://front-end.sock-shop.svc.cluster.local/\n  2. http://front-end.sock-shop.svc.cluster.local/catalogue?size=10\n  3. http://front-end.sock-shop.svc.cluster.local/detail.html?id=<ID>\n  Replace <ID> with an available ID: [`03fef6ac-1896-4ce8-bd69-b798f85c6e0b`, `3395a43e-2d88-40de-b95f-e00e1502085b`, `510a0d7e-8e83-4193-b483-e27e09ddc34d`, `808a2de1-1aaa-4c25-a9b9-6612e8f29a38`, `819e1fbf-8b7e-4f6d-811f-693534916a8b`, `837ab141-399e-4c1f-9abc-bace40296bac`, `a0a4f044-b040-410d-8ead-4de0446aec7e`, `d3588630-ad8e-49df-bbd7-3167f7efb246`, `zzz4f044-b040-410d-8ead-4de0446aec7e`]\n  4. http://front-end.sock-shop.svc.cluster.local/category/\n  5. http://front-end.sock-shop.svc.cluster.local/category?tags=<TAG>\n  Replace <TAG> with an available tag: [`magic`, `action`, `blue`, `brown`, `black`, `sport`, `formal`, `red`, `green`, `skin`, `geek`]\n  6. http://front-end.sock-shop.svc.cluster.local/basket.html\n\n## Step 1. Hypothesis definition\n### Here is the overview of the hypothesis for the system:\nThe hypothesis is \"The steady states of the sytem are maintained even when the fault scenario occurs (i.e., when the faults are injected)\".\nThe steady states here are as follows:\n2 steady states are defined.\n1st steady states:\n- Name: carts-db-replicas\n- Description: The first issue to address is 'Missing Resource Requests' in the 'carts-db' deployment. This is a critical issue because without resource requests, the pods may not get scheduled if the cluster is under resource pressure, leading to potential downtime. The 'carts-db' deployment is part of the database layer, which is crucial for the application's functionality. Ensuring that the 'carts-db' pods are running is essential for the system's steady state. Therefore, a steady state should be defined to ensure that the 'carts-db' deployment maintains its desired number of replicas, which is 2, to verify that the system can handle resource pressure without downtime.\n- Threshold for the steady state: At least 2 ready replicas for 'carts-db' must be maintained 95% of the time within a 1-minute monitoring period.; The steady state in question is the number of replicas for the 'carts-db' deployment. The current state shows that both the desired and ready replicas are consistently at 2, which is the expected number of replicas as per the deployment configuration. To ensure the system remains in a steady state, we need to define a threshold that accounts for potential fluctuations while still maintaining the necessary redundancy for reliability. Given that the system is expected to handle resource pressure without downtime, the threshold should ensure that at least 2 replicas are ready at any given time. However, to account for transient states during scaling or updates, a reasonable tolerance can be applied. Therefore, the threshold can be set such that at least 2 replicas are ready 95% of the time during the monitoring period, which is 1 minute as per the chaos engineering experiment constraints.\n- Whether the steady state meets the threshold is determined by the following Python script with K8s API:\n```\nimport os\nimport time\nimport argparse\nfrom kubernetes import client, config\nfrom unittest_base import K8sAPIBase\n\nclass TestCartsDBReplicas(K8sAPIBase):\n    def __init__(self, duration):\n        super().__init__()\n        self.duration = duration\n\n    def test_carts_db_replicas(self):\n        namespace = 'sock-shop'\n        deployment_name = 'carts-db'\n        v1 = client.AppsV1Api()\n\n        # Initialize counters\n        total_checks = 0\n        successful_checks = 0\n\n        # Check the deployment status for the specified duration\n        for _ in range(self.duration):\n            try:\n                deployment = v1.read_namespaced_deployment(deployment_name, namespace)\n                ready_replicas = deployment.status.ready_replicas or 0\n                print(f\"Ready replicas: {ready_replicas}\")\n\n                # Increment total checks\n                total_checks += 1\n\n                # Check if the ready replicas meet the threshold\n                if ready_replicas >= 2:\n                    successful_checks += 1\n\n            except client.exceptions.ApiException as e:\n                print(f\"Exception when calling AppsV1Api->read_namespaced_deployment: {e}\")\n\n            time.sleep(1)\n\n        # Calculate the percentage of successful checks\n        success_rate = (successful_checks / total_checks) * 100\n        print(f\"Success rate: {success_rate}%\")\n\n        # Assert that the success rate meets the 95% threshold\n        assert success_rate >= 95, f\"Threshold not met: {success_rate}% < 95%\"\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Test carts-db replicas')\n    parser.add_argument('--duration', type=int, default=60, help='Duration to check the replicas')\n    args = parser.parse_args()\n\n    # Create an instance of the test class with the specified duration\n    test = TestCartsDBReplicas(args.duration)\n    test.test_carts_db_replicas()\n\n\nif __name__ == '__main__':\n    main()\n```2nd steady states:\n- Name: front-end-replicas\n- Description: The next issue to address is 'Single Replica Deployment' in the 'front-end' deployment. This is a critical issue because having only one replica can lead to downtime if the pod fails. The front-end is a crucial component as it serves as the entry point for users interacting with the application. Ensuring that the front-end is always available is essential for the system's steady state. Therefore, a steady state should be defined to ensure that the 'front-end' deployment maintains its desired number of replicas, which is 1, to verify that the system can handle failures without downtime.\n- Threshold for the steady state: At least 1 ready replica for the 'front-end' deployment must be maintained 100% of the time during the 1-minute monitoring period.; The steady state in question is the number of replicas for the 'front-end' deployment. The current state shows that the desired replicas are 1 and the ready replicas are also 1, which means the system is currently in a stable state. However, having only one replica is a potential risk for downtime if the pod fails. To ensure the system remains stable and can handle failures without downtime, the threshold should be set to ensure that at least 1 replica is always ready. Given the constraints of the chaos engineering experiment, which must be completed within 1 minute, and the fact that the current state is stable with 1 ready replica, the threshold should be set to ensure that the 'front-end' deployment maintains at least 1 ready replica 100% of the time during the monitoring period. This threshold accounts for the current state and ensures that the system remains stable under normal conditions.\n- Whether the steady state meets the threshold is determined by the following Python script with K8s API:\n```\nimport os\nimport time\nimport argparse\nfrom kubernetes import client, config\nfrom unittest_base import K8sAPIBase\n\nclass TestFrontEndReplicas(K8sAPIBase):\n    def __init__(self, namespace, deployment_name, duration):\n        super().__init__()\n        self.namespace = namespace\n        self.deployment_name = deployment_name\n        self.duration = duration\n        # Use AppsV1Api for deployment operations\n        self.apps_v1 = client.AppsV1Api()\n\n    def test_steady_state(self):\n        # Initialize variables to track the number of successful checks\n        successful_checks = 0\n\n        # Loop for the specified duration\n        for _ in range(self.duration):\n            try:\n                # Read the deployment status\n                deployment = self.apps_v1.read_namespaced_deployment(self.deployment_name, self.namespace)\n                ready_replicas = deployment.status.ready_replicas or 0\n\n                # Check if the number of ready replicas is at least 1\n                if ready_replicas >= 1:\n                    successful_checks += 1\n\n            except client.exceptions.ApiException as e:\n                print(f\"Exception when calling AppsV1Api->read_namespaced_deployment: {e}\")\n\n            # Wait for 1 second before the next check\n            time.sleep(1)\n\n        # Calculate the success ratio\n        success_ratio = successful_checks / self.duration\n\n        # Assert that the success ratio is 100%\n        assert success_ratio == 1.0, f\"Steady state not maintained: {success_ratio * 100}% of the time\"\n\n        # Print success message\n        print(\"Steady state maintained 100% of the time\")\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Test front-end replicas steady state')\n    parser.add_argument('--duration', type=int, default=60, help='Duration to check the replicas')\n    args = parser.parse_args()\n\n    # Create an instance of the test class\n    test = TestFrontEndReplicas('sock-shop', 'front-end', args.duration)\n\n    # Run the test\n    test.test_steady_state()\n\n\nif __name__ == '__main__':\n    main()\n\n```\n\nThe fault scenario here is as follows:\n\nAn assumed fault scenario is as follows:\n- Event: Black Friday Sale\n- Used Chaos Engineering tool: Chaos Mesh\n- Faults to simulate the event: [[Fault(name='StressChaos', name_id=0, params={'mode': 'all', 'selector': {'namespaces': ['sock-shop'], 'labelSelectors': {'name': 'carts-db'}}, 'stressors': {'cpu': {'workers': 2, 'load': 100}, 'memory': {'workers': 2, 'size': '256MB'}}, 'containerNames': ['carts-db']})], [Fault(name='PodChaos', name_id=1, params={'action': 'pod-kill', 'mode': 'one', 'selector': {'namespaces': ['sock-shop'], 'labelSelectors': {'name': 'front-end'}}})]]\n- Description: During a Black Friday sale, the system is expected to handle a significant increase in traffic and load. This event will test the system's ability to maintain steady states under high demand. The primary weaknesses identified are missing resource requests for critical database components and a single replica for the front-end service. These weaknesses could lead to resource contention and downtime, respectively. To simulate the Black Friday event, we will first inject a StressChaos to simulate high CPU and memory usage on the 'carts-db' deployment, which lacks resource requests. This will test if the system can maintain the 'carts-db-replicas' steady state under resource pressure. Next, we will inject a PodChaos to kill the single replica of the 'front-end' deployment to test if the system can maintain the 'front-end-replicas' steady state and recover quickly. This sequence simulates the phenomena of high demand and potential failures during a Black Friday sale, targeting the system's identified weaknesses.\n\n## Step 2.1. Chaos-Engineering experiment\n### Here is the overview of my Chaos-Engineering experiment to verify the hypothesis:\nThe entire time schedule of the Chaos-Engineering experiment is as follows (The experiment is divided into three phases: pre-validation, fault-injection, and post-validation phases):\nThe chaos engineering experiment is designed to test the system's resilience under simulated fault conditions, specifically during a high-demand event like a Black Friday sale. The experiment is divided into three phases: pre-validation, fault-injection, and post-validation. Given the constraints that the entire experiment must be completed within 1 minute, we need to allocate time efficiently across these phases. \n\n1. **Pre-validation Phase**: This phase ensures that the system is in a steady state before any faults are injected. We will allocate 15 seconds for this phase. During this time, we will verify that the 'carts-db' deployment maintains at least 2 ready replicas 95% of the time and that the 'front-end' deployment maintains at least 1 ready replica 100% of the time. This is crucial to establish a baseline for the system's normal operation.\n\n2. **Fault-injection Phase**: This phase involves injecting faults to simulate the Black Friday event. We will allocate 30 seconds for this phase. The faults include a StressChaos on the 'carts-db' deployment to simulate high CPU and memory usage, and a PodChaos to kill the single replica of the 'front-end' deployment. This phase is critical to observe how the system behaves under stress and failure conditions.\n\n3. **Post-validation Phase**: This phase checks if the system returns to its steady state after the faults are removed. We will allocate 15 seconds for this phase. Similar to the pre-validation phase, we will verify the steady states of the 'carts-db' and 'front-end' deployments to ensure that the system can recover and maintain its expected performance.\n\nThe total time for the experiment is 60 seconds, with 15 seconds for pre-validation, 30 seconds for fault injection, and 15 seconds for post-validation. This allocation allows us to thoroughly test the system's resilience while adhering to the time constraint.\n- Total experiment phase: 60s\n- Pre-validation phase: 15s\n- Fault-injection phase: 30s\n- Post-validation phase: 15s\n\nThe details of the three phases are as follows:\nPre-validation Phase (15s):\nIn the pre-validation phase, we need to ensure that the system is in a steady state before we proceed with fault injection. Given the constraints of a 15-second total time for this phase, we will focus on verifying the two defined steady states: 'carts-db-replicas' and 'front-end-replicas'. These checks will be executed sequentially due to the short time frame, ensuring that each steady state is verified independently. The 'carts-db-replicas' steady state will be checked first, as it involves verifying that at least 2 replicas are ready 95% of the time within a 1-minute monitoring period. However, for the pre-validation phase, we will adjust the check to fit within the 15-second window, ensuring that the system is stable at the start of the experiment. Following this, we will verify the 'front-end-replicas' steady state, ensuring that at least 1 replica is ready 100% of the time during the 15-second pre-validation period. This approach ensures that both critical components are functioning as expected before introducing any faults.\n\nFault-injection Phase (30s):\nThe fault-injection phase is designed to simulate a Black Friday sale scenario, which involves high demand and potential failures. The goal is to test the system's ability to maintain its steady states under these conditions. Given the constraints of a 30-second total time for this phase, we need to carefully schedule the fault injections to maximize the observation of system behavior while ensuring that the faults are impactful.\n\nFirst, we will inject a `StressChaos` fault targeting the `carts-db` deployment. This fault will simulate high CPU and memory usage, testing the system's ability to maintain the `carts-db-replicas` steady state under resource pressure. This fault will be injected at the start of the phase (grace period of 0s) and will last for 15 seconds. This duration is chosen to allow enough time for the system to react to the stress while leaving time for the next fault.\n\nNext, we will inject a `PodChaos` fault targeting the `front-end` deployment. This fault will kill the single replica of the `front-end` service, testing the system's ability to maintain the `front-end-replicas` steady state and recover quickly. This fault will be injected with a grace period of 15 seconds, starting immediately after the `StressChaos` fault ends, and will last for 15 seconds. This staggered approach ensures that each fault is isolated in time, allowing us to observe the system's response to each fault individually.\n\nThe unit tests for verifying the steady states will run concurrently with the fault injections. The `carts-db-replicas` unit test will start at the beginning of the phase and run for the entire 30 seconds, as it needs to monitor the system's ability to maintain the required number of replicas under stress. Similarly, the `front-end-replicas` unit test will also run for the entire 30 seconds, ensuring that the system can maintain at least one ready replica of the `front-end` service despite the pod-kill fault.\n\nPost-validation Phase (15s):\nIn the post-validation phase, we need to ensure that the system has returned to its steady states after the fault injection. Given the constraints of a 15-second total time for this phase, we will focus on quickly verifying the two steady states: 'carts-db-replicas' and 'front-end-replicas'. The approach is to run the unit tests for each steady state sequentially, as the time constraint does not allow for simultaneous execution. Each unit test will have a short grace period to allow the system to stabilize after the fault injection, followed by a brief duration to verify the steady state. The thought process is to prioritize the verification of the critical components affected by the fault injection, ensuring that the system can recover and maintain its expected behavior.\n\nThe summary of the above experiment plan:\nThe chaos engineering experiment is structured into three phases: pre-validation, fault-injection, and post-validation, all to be completed within a total of 60 seconds. \n\nIn the pre-validation phase, which lasts for 15 seconds, the system's steady state is verified before any faults are introduced. The verification of the 'carts-db-replicas' steady state is conducted first, with no waiting time before it starts, and it runs for 7 seconds. This is followed by the verification of the 'front-end-replicas' steady state, which begins immediately after the first verification ends, with a duration of 8 seconds. This sequential execution ensures that each component is independently verified for stability.\n\nThe fault-injection phase spans 30 seconds and is designed to simulate high-demand conditions. It begins with the injection of a 'StressChaos' fault on the 'carts-db' deployment, which starts immediately and lasts for 15 seconds. Following this, a 'PodChaos' fault is injected on the 'front-end' deployment, starting at the 15-second mark and also lasting for 15 seconds. Concurrently, unit tests for both 'carts-db-replicas' and 'front-end-replicas' run for the entire 30 seconds, starting at the beginning of the phase, to monitor the system's ability to maintain steady states under stress.\n\nIn the post-validation phase, which also lasts 15 seconds, the system's recovery to steady states is verified. The 'carts-db-replicas' steady state is checked first, starting immediately and running for 7 seconds. This is followed by the 'front-end-replicas' steady state verification, which begins at the 7-second mark and lasts for 8 seconds. This sequential approach ensures that the system's recovery is thoroughly validated after the fault conditions are removed.\n\nTo automatically conduct the above experiment plan with Chaos Mesh, the following Chaos-Mesh-Worfklow file was created (by applying it to the cluster, the experiment plan will be automatically executed according to the Chaos-Mesh-Worfklow file):\n```yaml\napiVersion: chaos-mesh.org/v1alpha1\nkind: Workflow\nmetadata:\n  name: chaos-experiment-20241127-030328\nspec:\n  entry: the-entry\n  templates:\n    #-------------------------------\n    # entry point of whole workflow\n    #-------------------------------\n    - name: the-entry\n      templateType: Serial\n      deadline: 31m\n      children:\n        - pre-validation-phase\n        - fault-injection-phase\n        - post-validation-phase\n\n    #-------------------------------------\n    # Entry point of pre-validation-phase\n    #-------------------------------------\n    - name: pre-validation-phase\n      templateType: Serial\n      deadline: 10m15s\n      children:\n        - pre-validation-overlapped-workflows\n    \n    - name: pre-validation-suspend-workflow\n      templateType: Serial\n      deadline: 5m15s\n      children:\n        - pre-validation-suspend\n        - pre-unittest-front-end-replicas\n\n    - name: pre-validation-suspend\n      templateType: Suspend\n      deadline: 7s\n\n    - name: pre-validation-overlapped-workflows\n      templateType: Parallel\n      deadline: 5m15s\n      children:\n        - pre-unittest-carts-db-replicas\n        - pre-validation-suspend-workflow\n\n    # Definitions of children of pre-validation-phase\n    - name: pre-unittest-carts-db-replicas\n      templateType: Task\n      deadline: 5m7s\n      task:\n        container:\n          name: pre-unittest-carts-db-replicas-container\n          image: chaos-eater/k8sapi:1.0\n          imagePullPolicy: IfNotPresent\n          command: [\"/bin/bash\", \"-c\"]\n          args: [\"python /chaos-eater/sandbox/cycle_20241127_024431/unittest_carts-db-replicas_mod0.py --duration 7\"]\n          volumeMounts:\n            - name: pvc-volume\n              mountPath: /chaos-eater\n        volumes:\n          - name: pvc-volume\n            persistentVolumeClaim:\n              claimName: pvc\n\n    - name: pre-unittest-front-end-replicas\n      templateType: Task\n      deadline: 5m8s\n      task:\n        container:\n          name: pre-unittest-front-end-replicas-container\n          image: chaos-eater/k8sapi:1.0\n          imagePullPolicy: IfNotPresent\n          command: [\"/bin/bash\", \"-c\"]\n          args: [\"python /chaos-eater/sandbox/cycle_20241127_024431/unittest_front-end-replicas_mod0.py --duration 8\"]\n          volumeMounts:\n            - name: pvc-volume\n              mountPath: /chaos-eater\n        volumes:\n          - name: pvc-volume\n            persistentVolumeClaim:\n              claimName: pvc\n    \n    #--------------------------------------\n    # Entry point of fault-injection-phase\n    #--------------------------------------\n    - name: fault-injection-phase\n      templateType: Serial\n      deadline: 10m30s\n      children:\n        - fault-injection-overlapped-workflows\n\n    - name: fault-injection-parallel-workflow\n      templateType: Parallel\n      deadline: 5m30s\n      children:\n        - fault-unittest-carts-db-replicas\n        - fault-unittest-front-end-replicas\n        - fault-stresschaos\n\n    - name: fault-injection-suspend-workflow\n      templateType: Serial\n      deadline: 30s\n      children:\n        - fault-injection-suspend\n        - fault-podchaos\n\n    - name: fault-injection-suspend\n      templateType: Suspend\n      deadline: 15s\n\n    - name: fault-injection-overlapped-workflows\n      templateType: Parallel\n      deadline: 5m30s\n      children:\n        - fault-injection-parallel-workflow\n        - fault-injection-suspend-workflow\n\n    # Definitions of children of pre-validation-phase\n    # unit tests\n    - name: fault-unittest-carts-db-replicas\n      templateType: Task\n      deadline: 5m30s\n      task:\n        container:\n          name: fault-unittest-carts-db-replicas-container\n          image: chaos-eater/k8sapi:1.0\n          imagePullPolicy: IfNotPresent\n          command: [\"/bin/bash\", \"-c\"]\n          args: [\"python /chaos-eater/sandbox/cycle_20241127_024431/unittest_carts-db-replicas_mod0.py --duration 30\"]\n          volumeMounts:\n            - name: pvc-volume\n              mountPath: /chaos-eater\n        volumes:\n          - name: pvc-volume\n            persistentVolumeClaim:\n              claimName: pvc\n\n    - name: fault-unittest-front-end-replicas\n      templateType: Task\n      deadline: 5m30s\n      task:\n        container:\n          name: fault-unittest-front-end-replicas-container\n          image: chaos-eater/k8sapi:1.0\n          imagePullPolicy: IfNotPresent\n          command: [\"/bin/bash\", \"-c\"]\n          args: [\"python /chaos-eater/sandbox/cycle_20241127_024431/unittest_front-end-replicas_mod0.py --duration 30\"]\n          volumeMounts:\n            - name: pvc-volume\n              mountPath: /chaos-eater\n        volumes:\n          - name: pvc-volume\n            persistentVolumeClaim:\n              claimName: pvc\n\n    # fault_injections\n    - name: fault-stresschaos\n      templateType: StressChaos\n      deadline: 15s\n      stressChaos:\n        containerNames:\n          - carts-db\n        mode: all\n        selector:\n          labelSelectors:\n            name: carts-db\n          namespaces:\n            - sock-shop\n        stressors:\n          cpu:\n            load: 100\n            workers: 2\n          memory:\n            size: 256MB\n            workers: 2\n\n\n    - name: fault-podchaos\n      templateType: PodChaos\n      deadline: 15s\n      podChaos:\n        action: pod-kill\n        mode: one\n        selector:\n          labelSelectors:\n            name: front-end\n          namespaces:\n            - sock-shop\n\n    \n    #--------------------------------------\n    # Entry point of post-validation phase\n    #--------------------------------------\n    - name: post-validation-phase\n      templateType: Serial\n      deadline: 10m15s\n      children:\n        - post-validation-overlapped-workflows\n\n    - name: post-validation-suspend-workflow\n      templateType: Serial\n      deadline: 5m15s\n      children:\n        - post-validation-suspend\n        - post-unittest-front-end-replicas\n\n    - name: post-validation-suspend\n      templateType: Suspend\n      deadline: 7s\n\n    - name: post-validation-overlapped-workflows\n      templateType: Parallel\n      deadline: 5m15s\n      children:\n        - post-unittest-carts-db-replicas\n        - post-validation-suspend-workflow\n\n    # Definitions of children of pre-validation-phase\n    - name: post-unittest-carts-db-replicas\n      templateType: Task\n      deadline: 5m7s\n      task:\n        container:\n          name: post-unittest-carts-db-replicas-container\n          image: chaos-eater/k8sapi:1.0\n          imagePullPolicy: IfNotPresent\n          command: [\"/bin/bash\", \"-c\"]\n          args: [\"python /chaos-eater/sandbox/cycle_20241127_024431/unittest_carts-db-replicas_mod0.py --duration 7\"]\n          volumeMounts:\n            - name: pvc-volume\n              mountPath: /chaos-eater\n        volumes:\n          - name: pvc-volume\n            persistentVolumeClaim:\n              claimName: pvc\n\n    - name: post-unittest-front-end-replicas\n      templateType: Task\n      deadline: 5m8s\n      task:\n        container:\n          name: post-unittest-front-end-replicas-container\n          image: chaos-eater/k8sapi:1.0\n          imagePullPolicy: IfNotPresent\n          command: [\"/bin/bash\", \"-c\"]\n          args: [\"python /chaos-eater/sandbox/cycle_20241127_024431/unittest_front-end-replicas_mod0.py --duration 8\"]\n          volumeMounts:\n            - name: pvc-volume\n              mountPath: /chaos-eater\n        volumes:\n          - name: pvc-volume\n            persistentVolumeClaim:\n              claimName: pvc\n```\n\n## Step 2.2, 3, 4. Experiment execution, analysis and improvement (reconfiguring the system to satisfy the hypothesis)\n### Here is the improvement history:\n### Experiment result (1st try)\nPassed unittests:\n- pre-unittest-carts-db-replicas\n- pre-unittest-front-end-replicas\n- fault-unittest-carts-db-replicas\n- post-unittest-carts-db-replicas\nFailed unittests:\n- fault-unittest-front-end-replicas\n```log\nTraceback (most recent call last):\n  File \"/chaos-eater/sandbox/cycle_20241127_024431/hypothesis/unittest_front-end-replicas_mod1.py\", line 60, in <module>\n    main()\n  File \"/chaos-eater/sandbox/cycle_20241127_024431/hypothesis/unittest_front-end-replicas_mod1.py\", line 56, in main\n    test.test_steady_state()\n  File \"/chaos-eater/sandbox/cycle_20241127_024431/hypothesis/unittest_front-end-replicas_mod1.py\", line 41, in test_steady_state\n    assert success_ratio == 1.0, f\"Steady state not maintained: {success_ratio * 100}% of the time\"\nAssertionError: Steady state not maintained: 43.333333333333336% of the time\n\n```\n\n- post-unittest-front-end-replicas\n```log\nTraceback (most recent call last):\n  File \"/chaos-eater/sandbox/cycle_20241127_024431/hypothesis/unittest_front-end-replicas_mod1.py\", line 60, in <module>\n    main()\n  File \"/chaos-eater/sandbox/cycle_20241127_024431/hypothesis/unittest_front-end-replicas_mod1.py\", line 56, in main\n    test.test_steady_state()\n  File \"/chaos-eater/sandbox/cycle_20241127_024431/hypothesis/unittest_front-end-replicas_mod1.py\", line 41, in test_steady_state\n    assert success_ratio == 1.0, f\"Steady state not maintained: {success_ratio * 100}% of the time\"\nAssertionError: Steady state not maintained: 87.5% of the time\n\n```\n\n\n\n### Analysis report (1st try)\nThe chaos engineering experiment aimed to test the system's resilience under simulated high-demand conditions, specifically focusing on the 'carts-db' and 'front-end' components. The experiment results indicate that while the 'carts-db' component maintained its steady state throughout the experiment, the 'front-end' component failed to do so during both the fault-injection and post-validation phases. \n\n1. **Analysis of 'carts-db' Component:**\n   - The 'carts-db' deployment successfully maintained its steady state, with at least 2 ready replicas 95% of the time, as required. This indicates that the system's configuration for 'carts-db', despite lacking explicit resource requests, was able to handle the simulated resource pressure from the 'StressChaos' fault. This success suggests that the current resource allocation and scheduling policies were sufficient to meet the demands placed on 'carts-db' during the experiment.\n\n2. **Analysis of 'front-end' Component:**\n   - The 'front-end' deployment failed to maintain its steady state during the fault-injection phase, with a success rate of only 43.33%. This failure is directly linked to the 'PodChaos' fault, which killed the single replica of the 'front-end' deployment. The lack of redundancy (only one replica) meant that any disruption led to immediate downtime, as evidenced by the failure to maintain the steady state.\n   - In the post-validation phase, the 'front-end' deployment's success rate improved to 87.5%, indicating partial recovery. However, this was still below the required 100% threshold, suggesting that the system took longer than expected to recover from the fault. This delay could be due to factors such as pod scheduling delays or insufficient resources to quickly bring the 'front-end' back online.\n\n3. **Insights and Recommendations:**\n   - **Increase Redundancy:** The primary issue with the 'front-end' component is the lack of redundancy. Increasing the number of replicas for the 'front-end' deployment from 1 to at least 2 would provide the necessary redundancy to handle pod failures without causing downtime.\n   - **Resource Requests and Limits:** While the 'carts-db' component managed to maintain its steady state, it is still advisable to define resource requests and limits for all deployments, including 'carts-db', to ensure consistent performance under varying load conditions.\n   - **Improved Recovery Mechanisms:** Investigate the reasons for the delayed recovery of the 'front-end' component post-fault. This could involve optimizing pod scheduling policies or ensuring that sufficient resources are available to quickly restart failed pods.\n\nIn conclusion, the experiment highlighted the critical need for redundancy in the 'front-end' component to prevent downtime during high-demand scenarios. Addressing this issue, along with defining resource requests and improving recovery mechanisms, will enhance the system's resilience and ability to maintain steady states under fault conditions.\n\n### Improvement result (1st try)\n2 K8s manifests are modified:\n- The K8s manifest 'sock-shop-2/manifests/09-front-end-dep.yaml' was replaced.\nIncrease the number of replicas for the 'front-end' deployment from 1 to 2 to provide redundancy and prevent downtime during pod failures.\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-end\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: front-end\n  template:\n    metadata:\n      labels:\n        name: front-end\n    spec:\n      containers:\n      - name: front-end\n        image: weaveworksdemos/front-end:0.3.12\n        resources:\n          limits:\n            cpu: 300m\n            memory: 1000Mi\n          requests:\n            cpu: 100m\n            memory: 300Mi\n        ports:\n        - containerPort: 8079\n        env:\n        - name: SESSION_REDIS\n          value: \"true\"\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n              - all\n          readOnlyRootFilesystem: true\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 300\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 30\n          periodSeconds: 3\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n```\n\n- The K8s manifest 'sock-shop-2/manifests/03-carts-db-dep.yaml' was replaced.\nAdd resource requests to the 'carts-db' deployment to ensure consistent performance under resource pressure.\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: carts-db\n  labels:\n    name: carts-db\n  namespace: sock-shop\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: carts-db\n  template:\n    metadata:\n      labels:\n        name: carts-db\n    spec:\n      containers:\n      - name: carts-db\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n        resources:\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          capabilities:\n            drop:\n              - all\n            add:\n              - CHOWN\n              - SETGID\n              - SETUID\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-volume\n      volumes:\n        - name: tmp-volume\n          emptyDir:\n            medium: Memory\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n```\n\n\n\n### Experiment result (2nd try)\nPassed unittests:\n- pre-unittest-carts-db-replicas\n- pre-unittest-front-end-replicas\n- fault-unittest-carts-db-replicas\n- fault-unittest-front-end-replicas\n- post-unittest-carts-db-replicas\n- post-unittest-front-end-replicas\nFailed unittests:\n\n\nPlease elaborate the above summary of a Chaos Engineering Cycle.\nAI: ```json\n{\"summary\":"
            ],
            "{\"summary\":\"The Chaos Engineering cycle involves a detailed examination and testing of a Kubernetes-based microservices application, specifically the Sock Shop e-commerce platform. The cycle begins with understanding the user inputs, which include various Kubernetes manifests that define the deployment and service configurations for different components of the application, such as carts, catalogue, orders, payment, and user services, along with their respective databases.\\n\\nThe system's resiliency issues are identified, including missing resource requests, single replica deployments, high initial delays for liveness probes, and missing port specifications in services. These issues could lead to potential downtime or connectivity problems under certain conditions.\\n\\nThe Chaos Engineering experiment is designed to test the hypothesis that the system can maintain its steady states even when faults are injected. Two steady states are defined: ensuring the 'carts-db' deployment maintains at least 2 ready replicas 95% of the time, and the 'front-end' deployment maintains at least 1 ready replica 100% of the time.\\n\\nThe experiment is divided into three phases: pre-validation, fault-injection, and post-validation, all to be completed within 1 minute. The pre-validation phase checks the system's steady state before fault injection. The fault-injection phase simulates a Black Friday sale scenario using Chaos Mesh, injecting StressChaos on the 'carts-db' deployment and PodChaos on the 'front-end' deployment. The post-validation phase verifies if the system returns to its steady state after the faults are removed.\\n\\nThe first experiment attempt revealed that while the 'carts-db' component maintained its steady state, the 'front-end' component failed to do so during the fault-injection and post-validation phases. The analysis suggested increasing redundancy for the 'front-end' deployment and defining resource requests for the 'carts-db' deployment.\\n\\nAfter implementing these improvements, the second experiment attempt was successful, with all unit tests passing, indicating that the system could maintain its steady states under the simulated fault conditions.\"}\n"
        ]
    }
]