{
    "steady_states": {
        "elems": [
            {
                "id": 0,
                "name": "example-pod-running",
                "description": "The first issue to address is the Pod's restart policy set to 'Never'. This is a critical issue because if the Pod fails, it will not restart, leading to potential downtime. Therefore, the steady state should ensure that the Pod is running and available. A measurable output for this steady state is the number of running Pods, which should be 1, as there is only one Pod defined in the manifest. This steady state will help verify that the Pod is up and running, which is crucial given the restart policy configuration.",
                "inspection": {
                    "tool_type": "k8s",
                    "duration": "5s",
                    "script": {
                        "path": "sandbox/cycle_20241124_132128/hypothesis/k8s_example-pod-running.py",
                        "content": "import os\nimport time\nfrom kubernetes import client, config\n\n# Load Kubernetes configuration based on the environment\nif os.getenv('KUBERNETES_SERVICE_HOST'):\n    config.load_incluster_config()\nelse:\n    config.load_kube_config()\n\nv1 = client.CoreV1Api()\n\ndef check_pod_status(namespace, pod_name):\n    try:\n        pod = v1.read_namespaced_pod(name=pod_name, namespace=namespace)\n        return pod.status.phase == 'Running'\n    except client.exceptions.ApiException as e:\n        print(f\"Exception when calling CoreV1Api->read_namespaced_pod: {e}\")\n        return False\n\ndef main(duration):\n    namespace = 'default'\n    pod_name = 'example-pod'\n    running_count = 0\n    for _ in range(duration):\n        if check_pod_status(namespace, pod_name):\n            running_count += 1\n        time.sleep(1)\n    print(f\"Pod '{pod_name}' running status checked {duration} times. Running count: {running_count}.\")\n\nif __name__ == '__main__':\n    import argparse\n    parser = argparse.ArgumentParser(description='Check if a pod is running.')\n    parser.add_argument('--duration', type=int, default=5, help='Duration to check the pod status in seconds.')\n    args = parser.parse_args()\n    main(args.duration)",
                        "work_dir": "sandbox/cycle_20241124_132128/hypothesis",
                        "fname": "k8s_example-pod-running.py"
                    },
                    "result": "Pod 'example-pod' running status checked 5 times. Running count: 5.\n"
                },
                "threshold": {
                    "threshold": "The pod should be running at least 90% of the time during the check period.",
                    "reason": "The steady state we are considering is whether the 'example-pod' is running. The current state shows that the pod was checked 5 times over a duration of 5 seconds, and it was running each time, resulting in a running count of 5. This indicates that the pod is consistently running during the check period. Given the constraints of the chaos engineering experiment, which must be completed within 1 minute, we can set a threshold that allows for some tolerance in case of brief fluctuations. A reasonable threshold would be that the pod should be running at least 90% of the time during the check period. This allows for a small margin of error while still ensuring that the pod is generally available and running."
                },
                "unittest": {
                    "path": "sandbox/cycle_20241124_132128/hypothesis/unittest_example-pod-running_mod0.py",
                    "content": "import os\nimport time\nimport argparse\nfrom kubernetes import client, config\nfrom unittest_base import K8sAPIBase\n\nclass TestPodRunningState(K8sAPIBase):\n    def __init__(self):\n        super().__init__()\n\n    def check_pod_status(self, namespace, pod_name):\n        try:\n            pod = self.v1.read_namespaced_pod(name=pod_name, namespace=namespace)\n            return pod.status.phase == 'Running'\n        except client.exceptions.ApiException as e:\n            print(f\"Exception when calling CoreV1Api->read_namespaced_pod: {e}\")\n            return False\n\n    def test_pod_running_state(self, duration):\n        namespace = 'default'\n        pod_name = 'example-pod'\n        running_count = 0\n\n        # Check the pod status every second for the specified duration\n        for _ in range(duration):\n            if self.check_pod_status(namespace, pod_name):\n                running_count += 1\n            time.sleep(1)\n\n        # Calculate the running percentage\n        running_percentage = (running_count / duration) * 100\n\n        # Assert that the running percentage is at least 90%\n        assert running_percentage >= 90, f\"Pod '{pod_name}' running percentage is below threshold: {running_percentage}%\"\n\n        print(f\"Pod '{pod_name}' running status checked {duration} times. Running percentage: {running_percentage}%.\")\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Test if a pod is running at least 90% of the time.')\n    parser.add_argument('--duration', type=int, default=5, help='Duration to check the pod status in seconds.')\n    args = parser.parse_args()\n\n    test = TestPodRunningState()\n    test.test_pod_running_state(args.duration)\n\n\nif __name__ == '__main__':\n    main()",
                    "work_dir": "sandbox/cycle_20241124_132128/hypothesis",
                    "fname": "unittest_example-pod-running_mod0.py"
                }
            },
            {
                "id": 1,
                "name": "example-service-availability",
                "description": "The next issue to address is the 'Single Pod Deployment', which is related to the lack of redundancy. This is a significant issue because if the single Pod fails, the service will be unavailable. To verify this, we can define a steady state that checks the availability of the service itself. A measurable output for this steady state is the service's response time or availability. Since the service is exposed on port 80, we can check if the service is responding to HTTP requests. This steady state will help verify that the service is available and responsive, which is crucial given the single Pod deployment configuration.",
                "inspection": {
                    "tool_type": "k6",
                    "duration": "5s",
                    "script": {
                        "path": "sandbox/cycle_20241124_132128/hypothesis/k6_example-service-availability.js",
                        "content": "import http from 'k6/http';\nimport { check } from 'k6';\n\nexport const options = {\n  vus: 1,\n  duration: '5s',\n};\n\nexport default function () {\n  const res = http.get('http://example-service.default.svc.cluster.local:80');\n  check(res, {\n    'status is 200': (r) => r.status === 200,\n  });\n}\n",
                        "work_dir": "sandbox/cycle_20241124_132128/hypothesis",
                        "fname": "k6_example-service-availability.js"
                    },
                    "result": "\n     \u2713 status is 200\n\n     checks.........................: 100.00% 13915 out of 13915\n     data_received..................: 12 MB   2.4 MB/s\n     data_sent......................: 1.5 MB  306 kB/s\n     http_req_blocked...............: avg=8.11\u00b5s   min=1.4\u00b5s    med=4.19\u00b5s   max=2.82ms   p(90)=6.47\u00b5s   p(95)=7.28\u00b5s  \n     http_req_connecting............: avg=2.23\u00b5s   min=0s       med=0s       max=345.12\u00b5s p(90)=0s       p(95)=0s      \n     http_req_duration..............: avg=236.57\u00b5s min=90.31\u00b5s  med=232.08\u00b5s max=3.38ms   p(90)=263.84\u00b5s p(95)=280.9\u00b5s \n       { expected_response:true }...: avg=236.57\u00b5s min=90.31\u00b5s  med=232.08\u00b5s max=3.38ms   p(90)=263.84\u00b5s p(95)=280.9\u00b5s \n     http_req_failed................: 0.00%   0 out of 13915\n     http_req_receiving.............: avg=67.9\u00b5s   min=17.89\u00b5s  med=61.39\u00b5s  max=2.36ms   p(90)=91.92\u00b5s  p(95)=99.14\u00b5s \n     http_req_sending...............: avg=18.51\u00b5s  min=4.66\u00b5s   med=14.77\u00b5s  max=2.51ms   p(90)=21.11\u00b5s  p(95)=23.45\u00b5s \n     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s      \n     http_req_waiting...............: avg=150.16\u00b5s min=54.98\u00b5s  med=151.23\u00b5s max=880.47\u00b5s p(90)=168.67\u00b5s p(95)=176.19\u00b5s\n     http_reqs......................: 13915   2782.666155/s\n     iteration_duration.............: avg=344.61\u00b5s min=131.12\u00b5s med=333.12\u00b5s max=3.98ms   p(90)=377.15\u00b5s p(95)=401.15\u00b5s\n     iterations.....................: 13915   2782.666155/s\n     vus............................: 1       min=1              max=1\n     vus_max........................: 1       min=1              max=1\n\n"
                },
                "threshold": {
                    "threshold": "Service availability should be at least 99.9% with a response status of 200.",
                    "reason": "The steady state we are considering is the availability of the 'example-service'. The k6 test results show that the service is currently responding with a 200 status code for all requests, indicating 100% availability. Given that the system consists of a single Pod, any failure in the Pod would result in the service being unavailable. Therefore, the threshold should ensure that the service remains available and responsive. To account for minor fluctuations and network latency, a reasonable threshold would be to maintain a high availability percentage, slightly below 100% to allow for brief, non-critical failures. A threshold of 99.9% availability is a common standard for web services, allowing for some tolerance while still ensuring high reliability."
                },
                "unittest": {
                    "path": "sandbox/cycle_20241124_132128/hypothesis/unittest_example-service-availability_mod0.js",
                    "content": "import http from 'k6/http';\nimport { check } from 'k6';\n\nexport const options = {\n  vus: 1,\n  duration: '5s',\n  thresholds: {\n    // Ensure that the service availability is at least 99.9%\n    'http_req_failed': ['rate<=0.001'], // 0.1% failure rate corresponds to 99.9% availability\n  },\n};\n\nexport default function () {\n  const res = http.get('http://example-service.default.svc.cluster.local:80');\n  check(res, {\n    'status is 200': (r) => r.status === 200,\n  });\n}\n",
                    "work_dir": "sandbox/cycle_20241124_132128/hypothesis",
                    "fname": "unittest_example-service-availability_mod0.js"
                }
            }
        ]
    },
    "fault": {
        "event": "Cyber Attack",
        "faults": [
            [
                {
                    "name": "PodChaos",
                    "name_id": 0,
                    "params": {
                        "action": "pod-kill",
                        "mode": "one",
                        "selector": {
                            "namespaces": [
                                "default"
                            ],
                            "labelSelectors": {
                                "app": "example"
                            }
                        }
                    }
                }
            ],
            [
                {
                    "name": "NetworkChaos",
                    "name_id": 1,
                    "params": {
                        "action": "delay",
                        "direction": "to",
                        "target": {
                            "mode": "all",
                            "selector": {
                                "namespaces": [
                                    "default"
                                ],
                                "labelSelectors": {
                                    "app": "example"
                                }
                            }
                        },
                        "mode": "all",
                        "selector": {
                            "namespaces": [
                                "default"
                            ],
                            "labelSelectors": {
                                "app": "example"
                            }
                        },
                        "device": "eth0",
                        "delay": {
                            "latency": "100ms",
                            "jitter": "10ms",
                            "correlation": "50"
                        }
                    }
                }
            ]
        ],
        "description": "Given the system's weaknesses, a cyber attack targeting the single Pod and its network could be highly impactful. The Pod's restart policy set to 'Never' means that if the Pod fails, it will not restart, leading to downtime. Additionally, the single Pod deployment means there is no redundancy, so any failure will make the service unavailable. To simulate a cyber attack, we can start by injecting a PodChaos fault to kill the Pod, testing the system's ability to handle Pod failures. This will directly exploit the lack of redundancy and the restart policy issue. Next, we can simulate a network attack using NetworkChaos to introduce network latency, testing the service's ability to maintain availability under network stress. This sequence simulates a cyber attack by first taking down the Pod and then stressing the network, revealing the system's vulnerabilities in handling such scenarios."
    }
}